{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Backpropagation and Neural Networks](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1184/lectures/cs231n_2017_lecture4.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Building Convolutional Neural Network using NumPy from Scratch](https://towardsdatascience.com/building-convolutional-neural-network-using-numpy-from-scratch-b30aac50e50a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.data\n",
    "import numpy as np\n",
    "img = skimage.data.chelsea()\n",
    "img = skimage.color.rgb2gray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_filter = np.zeros((2,3,3))\n",
    "\n",
    "l1_filter[0, :, :] = np.array(\n",
    "    [[\n",
    "        [-1, 0, 1],\n",
    "        [-1, 0, 1],\n",
    "        [-1, 0, 1]\n",
    "    ]]\n",
    ")\n",
    "\n",
    "l1_filter[1, :, :] = np.array(\n",
    "    [[\n",
    "        [1, 1, 1],\n",
    "        [0, 0, 0],\n",
    "        [-1, -1, -1]\n",
    "    ]]\n",
    ")\n",
    "\n",
    "def conv(img, conv_filter):\n",
    "    if len(img.shape) > 2 or len(conv_filter.shape) > 3:\n",
    "        if img.shape[-1] != conv_filter.shape[-1]:\n",
    "            print(\"Number of img channels != number of filters\")\n",
    "            sys.exit()\n",
    "    \n",
    "    if conv_filter.shape[1] != conv_filster.shape[2]:\n",
    "        print(\"Number of conv_filters size doesn't match!\")\n",
    "        sys.exit()\n",
    "    \n",
    "    if conv_filter.shape[1]%2 == 0:\n",
    "        print(\"Filter must have an odd size\")\n",
    "    \n",
    "    feature_maps = numpy.zeros((\n",
    "        img.shape[0] - conv_filter.shape[1] + 1,\n",
    "        img.shape[1] - conv_filter.shape[1] + 1,\n",
    "        conv_filter.shape[0]\n",
    "    ))\n",
    "    \n",
    "    #convolving\n",
    "    for filter_num in range(conv_filter.shape[0]):\n",
    "        print(\"Filter: \", filster_num + 1)\n",
    "        cur_filter = conv_filster[filter_num, :]\n",
    "        \n",
    "        if len(cur_filter.shape) > 2:\n",
    "            conv_map = conv_(img[:,:, 0], curr_filter[:, :, 0])\n",
    "            \n",
    "            for ch_num in range(1, cur_filter[-1]):\n",
    "                conv_map = conv_map + conv_(img[:,:,ch_num], cur_filter[:,:, ch_num])\n",
    "        else:\n",
    "            conv_map = conv_(img, curr_filter)\n",
    "        \n",
    "        feature_maps[:,:, filter_num] = conv_map\n",
    "    return feature_maps\n",
    "\n",
    "def conv_(img, conv_filter):\n",
    "    filter_size = conv_filter.shape[1]\n",
    "    result = np.zeros((img.shape))\n",
    "    for r in np.uint16(np.arange(filter_size/2.0, img.shape[0]-filter_size/2.0+1)):\n",
    "        for c in np.uint16(np.arange(filter_size/2.0, im.shape[1] - filter_size/2.0+1)):\n",
    "            cur_region = im[\n",
    "                r - np.uint16(np.floor(filter_size/2.0)):r+np.uint16(np.ceil(filter_size/2.0)),\n",
    "                c - np.uint16(np.floor(filter_size/2.0)):c+np.uint16(np.floor(filter_size/2.0))           \n",
    "                           ]\n",
    "            cur_res = cur_region * conv_filter\n",
    "            conv_sum = np.sum(cor_res)\n",
    "            result[r, c] = conv_sum\n",
    "    \n",
    "    final_result = result[\n",
    "        np.uint16(filter_size/2.0): result.shape[0] - np.uint16(filter_size/2.0),\n",
    "        np.uint16(filter_size/2.0): result.shape[1] - np.uint16(filter_size/2.0)\n",
    "                         ]\n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Tensorflow VAE example](https://www.tensorflow.org/tutorials/generative/cvae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os, time, numpy as np, glob\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import imageio\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(train_images, _), (test_images, _) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1).astype('float32')\n",
    "\n",
    "train_images /= 255.\n",
    "test_images /= 255.\n",
    "\n",
    "train_images[train_images >= .5] = 1.\n",
    "train_images[train_images < .5] = 0.\n",
    "test_images[test_images >= .5] = 1.\n",
    "test_images[test_images < .5] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BUF = 60000\n",
    "BATCH_SIZE = 100\n",
    "TEST_BUF = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(TRAIN_BUF).batch(BATCH_SIZE)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_images).shuffle(TEST_BUF).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(tf.keras.Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(CVAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.inference_net = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.InputLayer(input_shape=(28,28,1)),\n",
    "                tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=(2,2), activation='relu'),\n",
    "            ]\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
